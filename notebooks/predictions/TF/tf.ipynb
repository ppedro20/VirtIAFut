{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f5ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getenv(\"c:/Users/pedro/Desktop/VirtAIFut\"))\n",
    "\n",
    "df = pd.read_csv('../../../data/train/ss1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a7aaed",
   "metadata": {},
   "source": [
    "DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a coluna de índice de tempo para focar nas posições\n",
    "df = df.drop(columns=[\"frame_index\"])\n",
    "\n",
    "# Lista de entidades (jogadores + bola)\n",
    "entity_names = df.columns.tolist()\n",
    "n_entities = len(entity_names)\n",
    "n_frames = len(df)\n",
    "\n",
    "# Função para converter string \"x,y\" em vetor [x, y]\n",
    "def parse_position(pos_str):\n",
    "    try:\n",
    "        x, y = map(float, pos_str.split(','))\n",
    "        return np.array([x, y])\n",
    "    except:\n",
    "        return np.array([np.nan, np.nan])  # Para valores ausentes\n",
    "\n",
    "# Inicializar e preencher matriz de posições\n",
    "positions_array = np.zeros((n_frames, n_entities, 2))\n",
    "for i, entity in enumerate(entity_names):\n",
    "    positions_array[:, i, :] = np.stack(df[entity].apply(parse_position).values)\n",
    "\n",
    "# Interpolar valores ausentes\n",
    "def interpolate_array(array):\n",
    "    for entity_idx in range(n_entities):\n",
    "        for coord in range(2):\n",
    "            series = array[:, entity_idx, coord]\n",
    "            mask = np.isnan(series)\n",
    "            not_nan = np.where(~mask)[0]\n",
    "            if len(not_nan) > 1:\n",
    "                array[:, entity_idx, coord] = np.interp(\n",
    "                    x=np.arange(n_frames),\n",
    "                    xp=not_nan,\n",
    "                    fp=series[not_nan]\n",
    "                )\n",
    "            else:\n",
    "                array[:, entity_idx, coord] = 0.0\n",
    "    return array\n",
    "\n",
    "positions_array = interpolate_array(positions_array)\n",
    "\n",
    "# Normalizar posições\n",
    "min_pos = np.nanmin(positions_array, axis=(0, 1))\n",
    "max_pos = np.nanmax(positions_array, axis=(0, 1))\n",
    "range_pos = max_pos - min_pos\n",
    "range_pos[range_pos == 0] = 1.0\n",
    "positions_array_norm = (positions_array - min_pos) / range_pos\n",
    "\n",
    "# Criar máscara de presença\n",
    "def generate_mask(df, entity_names):\n",
    "    mask = np.ones((n_frames, n_entities), dtype=np.float32)\n",
    "    for i, entity in enumerate(entity_names):\n",
    "        for t in range(n_frames):\n",
    "            if pd.isna(df.iloc[t][entity]):\n",
    "                mask[t, i] = 0.0\n",
    "    return mask\n",
    "\n",
    "mask_array = generate_mask(df, entity_names)\n",
    "\n",
    "# Parâmetros da sequência\n",
    "N, M = 10, 5\n",
    "num_samples = n_frames - N - M + 1\n",
    "X_norm = np.zeros((num_samples, N, n_entities, 2))\n",
    "Y_norm = np.zeros((num_samples, M, n_entities, 2))\n",
    "X_mask = np.zeros((num_samples, N, n_entities))\n",
    "Y_mask = np.zeros((num_samples, M, n_entities))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    X_norm[i] = positions_array_norm[i:i+N]\n",
    "    Y_norm[i] = positions_array_norm[i+N:i+N+M]\n",
    "    X_mask[i] = mask_array[i:i+N]\n",
    "    Y_mask[i] = mask_array[i+N:i+N+M]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5b229",
   "metadata": {},
   "source": [
    "MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from notebooks.predictions.TF.trajectorytransformer import TrajectoryTransformer\n",
    "\n",
    "# Exemplo de uso\n",
    "model = TrajectoryTransformer()\n",
    "example_input = torch.tensor(X_norm, dtype=torch.float32)\n",
    "output = model(example_input)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc4f99",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b28538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Dataset e DataLoader ===\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from notebooks.predictions.TF.trajectorydataset import TrajectoryDataset\n",
    "\n",
    "# Criar dataset e dataloader\n",
    "train_dataset = TrajectoryDataset(X_norm, Y_norm, X_mask, Y_mask)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Treinamento do modelo ===\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 100\n",
    "model.train()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        if len(batch) == 4:\n",
    "            batch_X, batch_Y, batch_X_mask, batch_Y_mask = batch\n",
    "        else:\n",
    "            batch_X, batch_Y = batch\n",
    "\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_Y = batch_Y.to(device)\n",
    "\n",
    "        pred_Y = model(batch_X[:, -5:])  # usar os últimos 5 frames como entrada se necessário\n",
    "        loss = criterion(pred_Y, batch_Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_X = torch.tensor(X_norm[0:1], dtype=torch.float32).to(device)\n",
    "    pred_Y = model(sample_X[:, -5:])  # (1, 5, 22, 2)\n",
    "\n",
    "    # Desnormaliza a predição (de [0,1] para coordenadas reais)\n",
    "    pred_Y[..., 0] *= 12000\n",
    "    pred_Y[..., 1] *= 7000\n",
    "\n",
    "    print(\"Predicted trajectory shape:\", pred_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad25fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar modelo\n",
    "torch.save(model.state_dict(), '../../../data/models/trajectory_transformer.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
