{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT9Nv490zEnE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "s0gRS4zIzG40",
        "outputId": "af145693-3969-4b1b-c125-17b05efab735"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lPz8gw-zIuo"
      },
      "outputs": [],
      "source": [
        "# Load the new CSV file with interpolated data\n",
        "df = pd.read_csv('train_interpolated_combined.csv')\n",
        "\n",
        "# Melt to long format for easy manipulation\n",
        "df_long = df.melt(id_vars=[\"frame_index\"], var_name=\"entity\", value_name=\"position\")\n",
        "\n",
        "# Split 'position' into 'x' and 'y'\n",
        "df_long[['x', 'y']] = df_long['position'].str.split(',', expand=True).astype(float)\n",
        "\n",
        "# Helpers to extract player ID and team\n",
        "def extract_id(entity):\n",
        "    parts = entity.split('_')\n",
        "    if entity == 'ball' or len(parts) < 3:\n",
        "        return None\n",
        "    return parts[1]\n",
        "\n",
        "def extract_team(entity):\n",
        "    parts = entity.split('_')\n",
        "    if entity == 'ball' or len(parts) < 3:\n",
        "        return None\n",
        "    return parts[-1]\n",
        "\n",
        "# Add classification columns\n",
        "df_long[\"type\"] = df_long[\"entity\"].apply(lambda x: 'ball' if x == 'ball' else 'player')\n",
        "df_long[\"id\"] = df_long[\"entity\"].apply(extract_id)\n",
        "df_long[\"team\"] = df_long[\"entity\"].apply(extract_team)\n",
        "\n",
        "# Normalize positions\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "df_long['x_norm'] = scaler_x.fit_transform(df_long[['x']])\n",
        "df_long['y_norm'] = scaler_y.fit_transform(df_long[['y']])\n",
        "\n",
        "# Pivot to wide format for model input\n",
        "pivot_x = df_long.pivot(index='frame_index', columns='entity', values='x_norm')\n",
        "pivot_y = df_long.pivot(index='frame_index', columns='entity', values='y_norm')\n",
        "\n",
        "# Sort columns for consistency\n",
        "pivot_x = pivot_x.sort_index(axis=1)\n",
        "pivot_y = pivot_y.sort_index(axis=1)\n",
        "\n",
        "# Track sorted entity names\n",
        "entities = pivot_x.columns\n",
        "sorted_entities = list(entities)\n",
        "\n",
        "# Interleave x and y columns for LSTM input\n",
        "interleaved_data = np.empty((pivot_x.shape[0], pivot_x.shape[1] * 2))\n",
        "for idx, ent in enumerate(sorted_entities):\n",
        "    interleaved_data[:, idx * 2] = pivot_x[ent].values\n",
        "    interleaved_data[:, idx * 2 + 1] = pivot_y[ent].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sETsxNWAzLhd"
      },
      "outputs": [],
      "source": [
        "\n",
        "sequence_length = 30\n",
        "\n",
        "# Generate full sequences\n",
        "X, y = [], []\n",
        "for i in range(len(interleaved_data) - sequence_length):\n",
        "    X.append(interleaved_data[i:i+sequence_length])\n",
        "    y.append(interleaved_data[i+sequence_length])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# 80/20 split\n",
        "split_index = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bVHaRuzzOYl",
        "outputId": "2e1b9ae2-86df-4352-bad4-a7b88e059e20"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.losses import Huber\n",
        "\n",
        "# Modify the model architecture (e.g., add more units, layers, and regularization)\n",
        "\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(512, return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(256),\n",
        "    Dropout(0.3),\n",
        "    Dense(X_train.shape[2]),\n",
        "    ReLU()\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(0.0005), loss=Huber(), metrics=['mae'])\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "#model.compile(optimizer=Adam(0.0003), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Add a learning rate reduction callback\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.5)\n",
        "\n",
        "# Train the model with early stopping and learning rate reduction\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stopping, lr_reduction])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPB0dyU1zO6G",
        "outputId": "5f2875fb-1d32-45ba-bc28-ad1c9d81c172"
      },
      "outputs": [],
      "source": [
        "# Define train/test split and sequence length\n",
        "sequence_length = 30\n",
        "train_frames = int(0.8 * len(interleaved_data))\n",
        "predict_frames = len(interleaved_data) - train_frames\n",
        "\n",
        "# Start from last 10 frames of training\n",
        "input_seq = interleaved_data[train_frames - sequence_length:train_frames].copy()\n",
        "predicted_frames = []\n",
        "\n",
        "# Predict all future frames\n",
        "for i in range(predict_frames):\n",
        "    input_reshaped = input_seq[-sequence_length:].reshape(1, sequence_length, -1)\n",
        "    next_frame = model.predict(input_reshaped, verbose=0)[0]\n",
        "    predicted_frames.append(next_frame)\n",
        "    input_seq = np.vstack([input_seq, next_frame])\n",
        "\n",
        "# Reverse normalization\n",
        "predicted_frames = np.array(predicted_frames)\n",
        "reversed_predictions = []\n",
        "\n",
        "for frame in predicted_frames:\n",
        "    unnormalized_frame = []\n",
        "    for i in range(0, len(frame), 2):\n",
        "        x = scaler_x.inverse_transform(frame[i].reshape(-1, 1))[0][0]\n",
        "        y = scaler_y.inverse_transform(frame[i+1].reshape(-1, 1))[0][0]\n",
        "        unnormalized_frame.extend([x, y])\n",
        "    reversed_predictions.append(unnormalized_frame)\n",
        "\n",
        "# Create DataFrame\n",
        "output_columns = []\n",
        "for ent in sorted(entities):\n",
        "    output_columns.append(f\"{ent}_x\")\n",
        "    output_columns.append(f\"{ent}_y\")\n",
        "\n",
        "pred_df = pd.DataFrame(reversed_predictions, columns=output_columns)\n",
        "\n",
        "# Dynamic frame range\n",
        "pred_df.insert(0, \"frame\", range(train_frames, train_frames + len(pred_df)))\n",
        "pred_df.to_csv(f\"predicted_frames_{train_frames}_to_{train_frames + len(pred_df) - 1}.csv\", index=False)\n",
        "print(f\"âœ… Saved: predicted_frames_{train_frames}_to_{train_frames + len(pred_df) - 1}.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86ff16ec"
      },
      "outputs": [],
      "source": [
        "# Reverse normalization for ground truth (actual values)\n",
        "actual_gt = interleaved_data[train_frames:]\n",
        "actual_gt_unnorm = []\n",
        "\n",
        "for frame in actual_gt:\n",
        "    unnormalized_frame = []\n",
        "    for i in range(0, len(frame), 2):\n",
        "        x = scaler_x.inverse_transform(frame[i].reshape(-1, 1))[0][0]\n",
        "        y = scaler_y.inverse_transform(frame[i + 1].reshape(-1, 1))[0][0]\n",
        "        unnormalized_frame.extend([x, y])\n",
        "    actual_gt_unnorm.append(unnormalized_frame)\n",
        "\n",
        "actual_gt_unnorm = np.array(actual_gt_unnorm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbeb5dd0",
        "outputId": "0b122b04-b0e9-491b-ec17-058c789ef5ab"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Unnormalize\n",
        "predictions_un = scaler_x.inverse_transform(predictions[:, ::2]), scaler_y.inverse_transform(predictions[:, 1::2])\n",
        "y_test_un = scaler_x.inverse_transform(y_test[:, ::2]), scaler_y.inverse_transform(y_test[:, 1::2])\n",
        "\n",
        "# Flatten to calculate MAE, RMSE, etc.\n",
        "preds_flat = np.column_stack(predictions_un).flatten()\n",
        "actuals_flat = np.column_stack(y_test_un).flatten()\n",
        "\n",
        "mae = mean_absolute_error(actuals_flat, preds_flat)\n",
        "mse = mean_squared_error(actuals_flat, preds_flat)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(actuals_flat, preds_flat)\n",
        "\n",
        "print(f\"\\nðŸ“Š Evaluation Metrics:\")\n",
        "print(f\"MAE:  {mae:.4f}\")\n",
        "print(f\"MSE:  {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"RÂ²:   {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "57501d83",
        "outputId": "037f430b-4a8c-4337-cd2f-7bf223de669c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_entities = predicted_frames.shape[1] // 2\n",
        "sample_frames = 5\n",
        "\n",
        "for i in range(sample_frames):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    for j in range(num_entities):\n",
        "        pred_x = reversed_predictions[i][j * 2]\n",
        "        pred_y = reversed_predictions[i][j * 2 + 1]\n",
        "        act_x = actual_gt_unnorm[i][j * 2]\n",
        "        act_y = actual_gt_unnorm[i][j * 2 + 1]\n",
        "\n",
        "        plt.scatter(act_x, act_y, color='blue', label='Actual' if j == 0 else \"\")\n",
        "        plt.scatter(pred_x, pred_y, color='red', marker='x', label='Predicted' if j == 0 else \"\")\n",
        "        plt.plot([act_x, pred_x], [act_y, pred_y], color='gray', linestyle='dotted')\n",
        "\n",
        "    plt.title(f\"Frame {train_frames + i} - Actual vs Predicted\")\n",
        "    plt.xlabel(\"X\")\n",
        "    plt.ylabel(\"Y\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "9cd6ddcf",
        "outputId": "d5adbc7c-7fbb-474d-f824-1353a29adc1f"
      },
      "outputs": [],
      "source": [
        "# Example plot for a specific entity\n",
        "entity_index = 7  # Change this to inspect others\n",
        "print(f\"ðŸ” Entity Index {entity_index} corresponds to: {sorted_entities[entity_index]}\")\n",
        "\n",
        "# You must have variables `reversed_predictions` and `actual_gt_unnorm` defined before this.\n",
        "pred_xs = [frame[entity_index * 2] for frame in reversed_predictions]\n",
        "pred_ys = [frame[entity_index * 2 + 1] for frame in reversed_predictions]\n",
        "true_xs = [frame[entity_index * 2] for frame in actual_gt_unnorm]\n",
        "true_ys = [frame[entity_index * 2 + 1] for frame in actual_gt_unnorm]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(true_xs, true_ys, label='Actual Trajectory', color='blue')\n",
        "plt.plot(pred_xs, pred_ys, label='LSTM Prediction', color='red', linestyle='--')\n",
        "plt.title(f\"Full Trajectory - {sorted_entities[entity_index]}\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
